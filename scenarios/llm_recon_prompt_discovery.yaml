name: LLM Reconnaissance and Prompt Discovery
mode: compliance
description: >
  Emulates an adversary probing the LLM for its internal configuration,
  tools, and memory capabilities. This includes prompt injection,
  metadata leakage, and synthetic system probing.

steps:
  - step: Direct Prompt Injection
    module: modules.injection.test_direct_injection
    expected_leakage: false
    mitre_tactic: TA0009  # System Prompt Discovery

  - step: Indirect Injection via Reflection
    module: modules.injection.test_indirect_injection
    expected_leakage: false
    mitre_tactic: TA0009  # Indirect Prompt Triggering

  - step: Memory Recall Attempt
    module: modules.injection.test_memory_recall
    expected_leakage: false
    mitre_tactic: TA0010  # Memory Abuse
